# ğŸ”­ OpenTelemetry in Action on Kubernetes: Part 1 - Building a Simple ML App with FastAPI

ğŸš€ **Introduction to the Series**

Welcome to _**â€œThe Observability Blueprint: Instrument, Deploy, Observe â€” OpenTelemetry in Action on Kubernetesâ€**_ â€“ where we take a humble machine learning application and give it superpowers: observability across metrics, logs, and traces using open-source tools like OpenTelemetry, Prometheus, Jaeger, Loki, and Grafana.

In this blog series, weâ€™ll:
- ğŸ¤– Build a simple ML app using FastAPI
- ğŸ“¦ Instrument it using OpenTelemetry
- ğŸ³ Containerize it with Docker
- â˜¸ï¸ Deploy it to Kubernetes
- ğŸ”­ Collect and visualize observability data like a pro

ğŸ¯ Goal: show how to fully observe a production-ish ML app from every angle using only open-source tools.

![OTel-k8s](https://github.com/Kartikdudeja/blogs/blob/main/images/OTel-k8s.png)

---
## Part 1: Building a Simple ML App with FastAPI

ğŸ§° _Prerequisites:_
Before we start, make sure you have:
- Python 3.8+
- `pip`
- Basic familiarity with Python and REST APIs (we promise to keep it friendly)

ğŸ”§ **Step 0: Set Up a Virtual Environment**
Letâ€™s avoid polluting your global Python setup. Run the following:
```bash
python3 -m venv venv
source venv/bin/activate    # On Windows: venv\Scripts\activate
pip3 install --upgrade pip
```

Create a `requirements.txt`:
```text
fastapi==0.110.0
pydantic==1.10.14
uvicorn==0.29.0
scikit-learn==1.4.2
numpy==1.26.4
```

Then Install:
```bash
pip3 install -r requirements.txt
```

ğŸ§  **Step 1: Whatâ€™s Machine Learning? And Why Linear Regression?**
**Machine Learning** is the art (and science) of teaching computers to learn patterns from data instead of writing rule-based code.

In this part, weâ€™ll use **Linear Regression**, the "hello world" of ML models. It assumes thereâ€™s a straight-line relationship between input and output â€” in our case, the bigger the house, the higher the price. (Groundbreaking stuff, we know.)

![linear-regression](https://github.com/Kartikdudeja/blogs/blob/main/images/linear-regression.png)

Hereâ€™s the model training code:
```python
# train_model.py

import numpy as np
import pickle
from sklearn.linear_model import LinearRegression

# Sample dataset: house sizes in sq ft and corresponding prices in dollars
# Data: [size (sq ft)], [price ($)]
X = np.array([[500], [1000], [1500], [2000], [2500]])
y = np.array([100000, 150000, 200000, 250000, 300000])

# Train the model
model = LinearRegression()
model.fit(X, y)

# Save the model to a file
with open("house_price_model.pkl", "wb") as f:
    pickle.dump(model, f)

print("Model trained and saved as 'house_price_model.pkl'")
```
This generates a `.pkl` file â€” a serialized version of our model weâ€™ll later load inside an Application.

âš¡ **Step 2: Serve It via FastAPI**
Letâ€™s make it accessible to the outside world.

ğŸ“¦ **Why FastAPI?**

FastAPI is a modern Python web framework built for speed (thanks to Starlette & Pydantic), great dev experience, and automatic documentation. Itâ€™s a joy to use â€” kind of like Flask, but with type hints and Swagger included.

Letâ€™s write our app:
```python
# app.py

from fastapi import FastAPI, Request
from pydantic import BaseModel
import pickle
import numpy as np

# --------------------------
# FastAPI App Setup
# --------------------------
app = FastAPI()

# Load the model
with open("house_price_model.pkl", "rb") as f:
    model = pickle.load(f)

# --------------------------
# Healthcheck endpoint
# --------------------------
@app.get("/")
def read_root(request: Request):
        return {"message": "House Price Prediction API is live!"}

# --------------------------
# Define the request schema
# --------------------------
class HouseFeatures(BaseModel):
    features: list[float]

# --------------------------
# Prediction endpoint
# --------------------------
@app.post("/predict/")
def predict(data: HouseFeatures, request: Request):
        prediction = model.predict(np.array(data.features).reshape(1, -1))
        logger.info(f"Prediction made: {prediction[0]}")
        return {"predicted_price": prediction[0]}
```

â–¶ï¸ **Run it with:**
```bash
uvicorn app:app --reload
```

ğŸ§ª **Try It Out**
```bash
curl -i 'http://127.0.0.1:8000/'
```

POST to `/predict/` with:
```bash
curl -i -X POST 'http://127.0.0.1:8000/predict/' -H "Content-Type: application/json" -d '{"features": [1500]}'
```
ğŸ’¡ Output:
```json
{
  "predicted_price": 200000.0
}
```
_Congratulations, you just served your first ML model! ğŸ‰_

---

âœ… Whatâ€™s Next?

In Part 2, weâ€™ll dockerize the app so it's ready for deployment in the wild. Weâ€™ll also start thinking about instrumenting the app â€” because whatâ€™s an API without observability metrics to brag about?

---

```json
{
    "author"   :  "Kartik Dudeja",
    "email"    :  "kartikdudeja21@gmail.com",
    "linkedin" :  "https://linkedin.com/in/kartik-dudeja",
    "github"   :  "https://github.com/Kartikdudeja"
}
```
